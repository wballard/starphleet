#!/usr/bin/env bash
source `which tools`

info "building ${name}"

ORDER_LOCAL="${HEADQUARTERS_LOCAL}/${order}/git"
STATUS_FILE="${CURRENT_ORDERS}/${order}/.starphleetstatus.${name}"
RETRY_DOWNLOAD_FILE="${CURRENT_ORDERS}/${order}/.starphleetstatus.${name}.redownload"

run_orders "${HEADQUARTERS_LOCAL}/${order}/orders"

#pre stop if the service demands it
if [ "${STOP_BEFORE_AUTODEPLOY}" == "1" ]; then
  info stopping before autodeploy
  starphleet-reaper "${name}" "${order}" --force
fi

LAST_KNOWN_GOOD_CONTAINER=$(cat "${CURRENT_ORDERS}/${order}/.last_known_good_container" || true)
# this will give us the container name of the LKG ONLY IF the system has the
# container
DO_WE_HAVE_THE_LKG=$(lxc-ls | grep "^${LAST_KNOWN_GOOD_CONTAINER}$" || true)

# this 'use existing container' step is simply for optimizing restart of the
# LAST container we used, so we check to see if we're being asked to use the
# LKG and that we do indeed HAVE the LKG
if [ "${name}" == "${LAST_KNOWN_GOOD_CONTAINER}" -a "${name}" == "${DO_WE_HAVE_THE_LKG}" ]; then
  warn "using existing container ${name}"
  lxc-start --name ${name} -d
  starphleet-lxc-wait ${name} RUNNING
  lxc-attach --name ${name} -- bash starphleet-wait-network
  if dev_mode && [ -n "${DEVMODE_UNBIND_GIT_DIR}" ]; then
    lxc-attach --name ${name} -- sudo -H -u ${STARPHLEET_APP_USER} bash -c "rsync -rlKt '${ORDER_LOCAL}/' '/home/ubuntu/app/'"
    lxc-attach --name ${name} -- sudo -H -u ${STARPHLEET_APP_USER} bash -c "[ -f '${DEVMODE_BUILD_CACHE}' ] && rsync -rav --exclude-from='${DEVMODE_BUILD_CACHE}' --delete '${ORDER_LOCAL}/' '/home/ubuntu/app/'"
  fi
else
  warn "creating a new container"
  #starting up the build
  echo 'building' > "${STATUS_FILE}"
  starphleet-lxc-destroy "${name}"
  #build a container, this will recycle any existing container, only building
  #when things are 'new', with a default for said URL to be nothing
  starphleet-containerize "${SERVICE_GIT_URL:--}" "${name}" "${HEADQUARTERS_LOCAL}/${order}"
  CONTAINERIZE_EXIT_CODE=$?
  # If we are a serve-only server, it's possible containermake will fail
  # because the container does not yet exist in S3.  We want to keep trying
  # to get it indefinitely.  We accomplish that by letting the process
  # fail further downstream and use the mechanics in upstart to respawn
  if is_container_storage_on_s3 \
  && [ -z "${BUILD_CONTAINERS}" ] \
  && [ -n "${SERVE_CONTAINERS}" ] \
  && [ ${CONTAINERIZE_EXIT_CODE} -eq ${EXIT_CODE_FOR_FAILED_S3_DOWNLOADS} ]; then
    info 'Failed due to container not existing in S3 - Trying again'
    touch "${RETRY_DOWNLOAD_FILE}"
    exit 0
  fi

  if [ ${CONTAINERIZE_EXIT_CODE} -ne 0 ]; then
    echo 'Building Failed' > "${STATUS_FILE}"
    exit 1
  fi

  exit 0
fi
