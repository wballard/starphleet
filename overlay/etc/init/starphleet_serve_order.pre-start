#!/usr/bin/env bash
source `which tools`

info "building ${name}"

ORDER_LOCAL="${HEADQUARTERS_LOCAL}/${order}/git"
STATUS_FILE="${CURRENT_ORDERS}/${order}/.starphleetstatus.${name}"

run_orders "${HEADQUARTERS_LOCAL}/${order}/orders"

#pre stop if the service demands it
if [ "${STOP_BEFORE_AUTODEPLOY}" == "1" ]; then
  info stopping before autodeploy
  starphleet-reaper "${name}" "${order}" --force
fi

LAST_KNOWN_GOOD_CONTAINER=$(cat "${CURRENT_ORDERS}/${order}/.last_known_good_container" || true)
# this will give us the container name of the LKG ONLY IF the system has the
# container
DO_WE_HAVE_THE_LKG=$(lxc-ls | grep "^${LAST_KNOWN_GOOD_CONTAINER}$" || true)

# this 'use existing container' step is simply for optimizing restart of the
# LAST container we used, so we check to see if we're being asked to use the
# LKG and that we do indeed HAVE the LKG
if [ "${name}" == "${LAST_KNOWN_GOOD_CONTAINER}" -a "${name}" == "${DO_WE_HAVE_THE_LKG}" ]; then
  warn "using existing container ${name}"
  lxc-start --name ${name} -d
  starphleet-lxc-wait ${name} RUNNING
  lxc-attach --name ${name} -- bash starphleet-wait-network
  if dev_mode && [ -n "${DEVMODE_UNBIND_GIT_DIR}" ]; then
    lxc-attach --name ${name} -- sudo -H -u ${STARPHLEET_APP_USER} bash -c "rsync -rlKt '${ORDER_LOCAL}/' '/home/ubuntu/app/'"
    lxc-attach --name ${name} -- sudo -H -u ${STARPHLEET_APP_USER} bash -c "[ -f '${DEVMODE_BUILD_CACHE}' ] && rsync -rav --exclude-from='${DEVMODE_BUILD_CACHE}' --delete '${ORDER_LOCAL}/' '/home/ubuntu/app/'"
  fi
else
  warn "creating a new container"
  #starting up the build
  echo 'building' > "${STATUS_FILE}"
  starphleet-lxc-destroy "${name}"
  #build a container, this will recycle any existing container, only building
  #when things are 'new', with a default for said URL to be nothing
  starphleet-containerize "${SERVICE_GIT_URL:--}" "${name}" "${HEADQUARTERS_LOCAL}/${order}"
  CONTAINERIZE_EXIT_CODE=$?
  # If we are a serve-only server, it's possible containermake will fail
  # because the container does not yet exist in S3.  We want to keep trying
  # to get it indefinitely.  We accomplish that by letting the process
  # fail further downstream and use the mechanics in upstart to respawn
  if is_container_storage_on_s3 \
  && [ -z "${BUILD_CONTAINERS}" ] \
  && [ -n "${SERVE_CONTAINERS}" ] \
  && [ ${CONTAINERIZE_EXIT_CODE} -eq ${EXIT_CODE_FOR_FAILED_S3_DOWNLOADS} ]; then
    info 'Failed due to container not existing in S3 - Trying again'
    echo 'building failed' > "${STATUS_FILE}"
    # Least fancy way to trigger a full rebuild but still let us punt on
    # the pre-start instead of having to send signals further down the
    # upstart chain.  By removing the orders sha we can totally exit out
    # and monitor_orders will start us back up next cycle
    rm "${CURRENT_ORDERS}/${order}/.orders_sha"
    exit 1
  fi

  # Container Failed to Build on Build Server?
  if is_container_storage_on_s3 \
  && [ -n "${BUILD_CONTAINERS}" ] \
  && [ ${CONTAINERIZE_EXIT_CODE} -gt 0 ]; then
    info 'Container Failed To Build'
    echo 'building failed' > "${STATUS_FILE}"
    # Least fancy way to trigger a full rebuild but still let us punt on
    # the pre-start instead of having to send signals further down the
    # upstart chain.  By removing the orders sha we can totally exit out
    # and monitor_orders will start us back up next cycle.
    exit 1
  fi


  exit 0
fi
