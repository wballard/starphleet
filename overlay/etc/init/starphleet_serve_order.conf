
description "Starphleet order needs to be served, which is running a container for a given image version"

stop on stopping starphleet

#name is to let us have multiple running versions of the same order
instance $name
#also needs
# - $order: the directory where the ordered repository is cloned

respawn
respawn limit 3 600

# upstart doesn't use PAM by design, so limits are managed independently
# of other (PAM) mechanisms.  Since we're running all sorts of services
# here we want to set a limit that is seemingly large so folks have no
# problems, and at the same time is easy to identify as coming from here
limit nofile 65557 65557

pre-start script
  source `which tools`
  info "building ${name}"
  ORDER_LOCAL="${HEADQUARTERS_LOCAL}/${order}/git"
  get_CURRENT_SHA "${ORDER_LOCAL}"
  run_orders "${HEADQUARTERS_LOCAL}/${order}/orders"

  #pre stop if the service demands it
  if [ "${STOP_BEFORE_AUTODEPLOY}" == "1" ]; then
    info stopping before autodeploy
    starphleet-reaper "${name}" "${order}"
  fi

  LAST_KNOWN_GOOD_CONTAINER=$(cat "${CURRENT_ORDERS}/${order}/.last_known_good_container" || true)
  # this will give us the container name of the LKG ONLY IF the system has the
  # container
  DO_WE_HAVE_THE_LKG=$(lxc-ls | grep "^${LAST_KNOWN_GOOD_CONTAINER}$" || true)

  # this 'use existing container' step is simply for optimizing restart of the 
  # LAST container we used, so we check to see if we're being asked to use the
  # LKG and that we do indeed HAVE the LKG
  if [ "${name}" == "${LAST_KNOWN_GOOD_CONTAINER}" -a "${name}" == "${DO_WE_HAVE_THE_LKG}" ]; then
    warn "using existing container ${name}"
    lxc-start --name ${name} -d
    starphleet-lxc-wait ${name} RUNNING
    lxc-attach --name ${name} -- bash starphleet-wait-network
  else
    warn "creating a new container"
    #starting up the build
    echo 'building' > "${CURRENT_ORDERS}/${order}/.starphleetstatus"
    starphleet-lxc-destroy "${name}"
    #build a container, this will recycle any existing container, only building
    #when things are 'new'
    if [ dev_mode ]; then
      starphleet-containerize "${SERVICE_GIT_URL}" "${name}" "${HEADQUARTERS_LOCAL}/${order}" \
      || (echo 'building failed' > "${CURRENT_ORDERS}/${order}/.starphleetstatus" && exit 1)
    else
      starphleet-containerize "${ORDER_LOCAL}#${CURRENT_SHA}" "${name}" "${HEADQUARTERS_LOCAL}/${order}" \
      || (echo 'building failed' > "${CURRENT_ORDERS}/${order}/.starphleetstatus" && exit 1)
    fi  
  fi
  #this file is just a name pointer to the current container
  echo "${name}" > "${CURRENT_ORDERS}/${order}/.container"
end script

script
  source `which tools`
  info "starting ${name}"
  ORDER_LOCAL="${HEADQUARTERS_LOCAL}/${order}/git"
  get_CURRENT_SHA "${ORDER_LOCAL}"
  lxc-attach --name ${name} -- sudo -H -u ${STARPHLEET_APP_USER} bash -c "2>&1 setsid ~/start web" | logger -t "${order}" || mail_log
  echo 'stopped' > "${CURRENT_ORDERS}/${order}/.starphleetstatus"
end script

post-start script
  set +e
  source `which tools`
  info "checking ${name}"
  ORDER_LOCAL="${HEADQUARTERS_LOCAL}/${order}/git"
  get_CURRENT_SHA "${ORDER_LOCAL}"
  run_orders "${HEADQUARTERS_LOCAL}/${order}/orders"
  #status logging, here indicating the healthcheck is about to go
  echo 'checking' > "${CURRENT_ORDERS}/${order}/.starphleetstatus"

  #the container and service is started, so healthcheck it before we publish it
  #in order to have a real drainstop / transparent upgrade feature
  #if there is a specified healthcheck url
  if [ -z "${HEALTHCHECK}" ] || starphleet-ready "${name}" "${PORT}" "${HEALTHCHECK}"; then
    #at this point we have a running container, and it answers HTTP, so we
    #are on the air and can expose it via nginx
    #new versions replace old versions in nginx for the HUP update
    #http basic password authentication access
    if [ -f "${HEADQUARTERS_LOCAL}/${order}/.htpasswd" ]; then
      HTPASSWD="${HEADQUARTERS_LOCAL}/${order}/.htpasswd"
    else
      HTPASSWD='-'
    fi
    #and LDAP access, almost the same kind of thing -- but LDAPy
    if [ -f "${HEADQUARTERS_LOCAL}/${order}/.ldap" ]; then
      LDAP="${HEADQUARTERS_LOCAL}/${order}/.ldap"
    else
      LDAP='-'
    fi
    trace "${name}" "${PORT}" "${PUBLISH_PORT}" "/${order}" "${HTPASSWD}" "${LDAP}"
    if ! starphleet-publish "${name}" "/${order}" "${HEADQUARTERS_LOCAL}/${order}/orders" "${HTPASSWD}" "${LDAP}" ; then
      echo 'publish failed' > "${CURRENT_ORDERS}/${order}/.starphleetstatus"
      exit 1
    fi
    #record online, with the IP address of the container
    echo 'online' > "${CURRENT_ORDERS}/${order}/.starphleetstatus"
    echo "${name}" > "${CURRENT_ORDERS}/${order}/.last_known_good_container"
    lxc-ls --fancy "${name}" | tail -1 | awk '{ print $3; }' > "${CURRENT_ORDERS}/${order}/.starphleetstatus.ip"
    #any prior version of this order should now be reaped after
    #we wait a small time for prior requests to flush out
    sleep ${STARPHLEET_DRAINSTOP_WAIT}
    starphleet-reaper "${name}" "${order}"
    exit 0
  else
    #at this point the service has failed to properly start
    warn service failed to publish "/${order}"
    echo 'failed' > "${CURRENT_ORDERS}/${order}/.starphleetstatus"
    mail_log
    exit 1
  fi
end script

post-stop script
  source `which tools`
  starphleet-lxc-stop "${name}"
  if [ "${PROCESS}" == "respawn" ]; then
    # remove the last known good indicator so we don't re-use anything
    # if we've encountered a problems starting the container (hit the
    # respawn limit ) 
    rm "${CURRENT_ORDERS}/${order}/.last_known_good_container"
  fi
end script
